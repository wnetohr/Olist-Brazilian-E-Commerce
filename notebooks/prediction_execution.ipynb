{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from LeIA import SentimentIntensityAnalyzer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom transformer for sentiment analysis using LeIA\n",
    "class SentimentAnalyzer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.analyzer = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        compound_scores = []\n",
    "        neg_scores = []\n",
    "        pos_scores = []\n",
    "        neu_scores = []\n",
    "\n",
    "        for review in X:\n",
    "            s = self.analyzer.polarity_scores(review)\n",
    "            compound_scores.append(s['compound'])\n",
    "            neg_scores.append(s['neg'])\n",
    "            pos_scores.append(s['pos'])\n",
    "            neu_scores.append(s['neu'])\n",
    "        \n",
    "        polarity = np.select(\n",
    "            [np.array(compound_scores) > 0.0, np.array(compound_scores) < 0.0, np.array(compound_scores) == 0.0],\n",
    "            [1, -1, 0]\n",
    "        )\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            'comp_score': compound_scores,\n",
    "            'neg': neg_scores,\n",
    "            'pos': pos_scores,\n",
    "            'neu': neu_scores,\n",
    "            'polarity': polarity\n",
    "        })\n",
    "\n",
    "def create_pipeline():\n",
    "    # Define text and numeric processing\n",
    "    text_features = Pipeline([\n",
    "        ('sentiment', SentimentAnalyzer()),\n",
    "    ])\n",
    "    \n",
    "    numeric_features = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    # Create preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', text_features, 'review_comment_message'),  # Use the correct column name here\n",
    "            ('num', numeric_features, [\n",
    "                'payment_installments', 'payment_value', 'product_name_length',\n",
    "                'product_description_length', 'product_photos_qty', 'product_weight_g',\n",
    "                'freight_value_factor', 'actual_est_delivery_diff',\n",
    "                'delivery_duration', 'delivery_time_diff'\n",
    "            ])\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Full pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('clf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "# Load and prepare the data\n",
    "def load_data(file_path):\n",
    "    return pd.read_parquet(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp',\n",
      "       'order_approved_at', 'order_delivered_carrier_date',\n",
      "       'order_delivered_customer_date', 'order_estimated_delivery_date',\n",
      "       'review_id', 'review_score', 'review_comment_title',\n",
      "       'review_comment_message', 'review_creation_date',\n",
      "       'review_answer_timestamp', 'payment_sequential', 'payment_type',\n",
      "       'payment_installments', 'payment_value', 'customer_unique_id',\n",
      "       'customer_zip_code_prefix', 'customer_city', 'customer_state',\n",
      "       'order_item_id', 'product_id', 'seller_id', 'shipping_limit_date',\n",
      "       'price', 'freight_value', 'product_category_name',\n",
      "       'product_name_length', 'product_description_length',\n",
      "       'product_photos_qty', 'product_weight_g', 'product_length_cm',\n",
      "       'product_height_cm', 'product_width_cm', 'seller_zip_code_prefix',\n",
      "       'seller_city', 'seller_state', 'comp_score', 'neg', 'pos', 'neu',\n",
      "       'polarity', 'review_score_factor', 'price_factor',\n",
      "       'freight_value_factor', 'if_delivered', 'actual_est_delivery_diff',\n",
      "       'delivery_duration', 'delivery_time_diff', 'delivery'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mater\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mater\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "file_path6 = '../data/outputs/score_df_3.parquet' # Filtro 1 // 2, 3 e 4 // 5\n",
    "df = load_data(file_path6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add derived features\n",
    "df['freight_value_factor'] = np.where(df['freight_value'] >= df['freight_value'].median(), 1, 0)\n",
    "\n",
    "# Prepare training data\n",
    "df_train = df.copy()\n",
    "X = df_train.drop('review_score', axis=1, errors='ignore')\n",
    "y = df_train.get('review_score', pd.Series(np.zeros(len(df)), name='review_score'))\n",
    "\n",
    "# Drop 'price_factor' from the dataset\n",
    "X = X.drop(['price_factor'], axis=1, errors='ignore')\n",
    "\n",
    "# Create and train model\n",
    "model_rf = create_pipeline()\n",
    "model_rf.fit(X, y)\n",
    "\n",
    "# Function to predict rating based on user input\n",
    "def predict_rating(review_text, payment_installments, payment_value, product_name_length, \n",
    "                   product_description_length, product_photos_qty, product_weight_g, \n",
    "                   actual_est_delivery_diff, delivery_duration, delivery_time_diff):\n",
    "    # Create DataFrame for new input\n",
    "    new_data = pd.DataFrame({\n",
    "        'review_comment_message': [review_text],\n",
    "        'payment_installments': [payment_installments],\n",
    "        'payment_value': [payment_value],\n",
    "        'product_name_length': [product_name_length],\n",
    "        'product_description_length': [product_description_length],\n",
    "        'product_photos_qty': [product_photos_qty],\n",
    "        'product_weight_g': [product_weight_g],\n",
    "        'freight_value_factor': [np.where(product_weight_g >= df['freight_value'].median(), 1, 0)],\n",
    "        'actual_est_delivery_diff': [actual_est_delivery_diff],\n",
    "        'delivery_duration': [delivery_duration],\n",
    "        'delivery_time_diff': [delivery_time_diff]\n",
    "    })\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model_rf.predict(new_data)\n",
    "    \n",
    "    return prediction[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted rating for the review is: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "review_text = \"odiei a compra\"\n",
    "payment_installments = 10\n",
    "payment_value = 1.0\n",
    "product_name_length = 20\n",
    "product_description_length = 10\n",
    "product_photos_qty = 1\n",
    "product_weight_g = 5000\n",
    "actual_est_delivery_diff = 1\n",
    "delivery_duration = 100\n",
    "delivery_time_diff = 1\n",
    "\n",
    "predicted_rating = predict_rating(review_text, payment_installments, payment_value, \n",
    "                                   product_name_length, product_description_length, \n",
    "                                   product_photos_qty, product_weight_g, \n",
    "                                   actual_est_delivery_diff, delivery_duration, \n",
    "                                   delivery_time_diff)\n",
    "\n",
    "print(f\"The predicted rating for the review is: {predicted_rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
